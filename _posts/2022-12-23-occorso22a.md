---
title: Trust Region Meta Learning for Policy Optimization
section: Original Papers
abstract: Reinforcement Learning aims to train autonomous agents in their interaction
  with the environment by means of maximizing a given reward signal; in the last decade
  there has been an explosion of new algorithms, which make extensive use of hyper-parameters
  to control their behaviour, accuracy and speed. Often those hyper-parameters are
  fine-tuned by hand, and the selected values may change drastically the learning
  performance of the algorithm; furthermore, it happens to train multiple agents on
  very similar problems, starting from scratch each time. Our goal is to design a
  Meta-Reinforcement Learning algorithm to optimize the hyper-parameter of a well-known
  RL algorithm, named Trust Region Policy Optimization. We use knowledge from previous
  learning sessions and another RL algorithm, Fitted-Q Iteration, to build a policy-agnostic
  Meta-Model capable to predict the optimal hyper-parameter for TRPO at each of its
  steps, on new unseen problems, generalizing across different tasks and policy spaces.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: occorso22a
month: 0
tex_title: Trust Region Meta Learning for Policy Optimization
firstpage: 62
lastpage: 74
page: 62-74
order: 62
cycles: false
bibtex_author: Occorso, Manuel and Sabbioni, Luca and Metelli, Alberto Maria and Restelli,
  Marcello
author:
- given: Manuel
  family: Occorso
- given: Luca
  family: Sabbioni
- given: Alberto Maria
  family: Metelli
- given: Marcello
  family: Restelli
date: 2022-12-23
address:
container-title: ECMLPKDD Workshop on Meta-Knowledge Transfer
volume: '191'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 12
  - 23
pdf: https://proceedings.mlr.press/v191/occorso22a/occorso22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
